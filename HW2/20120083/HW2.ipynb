{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBgThS8q8k3"
      },
      "source": [
        "Full name: Nguyễn Trọng Hiếu\n",
        "\n",
        "Student ID: 20120083"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdrvDrCrnqz"
      },
      "source": [
        "# HW2: Parallel Execution in CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKXB0wA7yhq9"
      },
      "source": [
        "**To compile your file, you can use this command:** \\\n",
        "`nvcc tên-file.cu -o tên-file-chạy` \\\n",
        "***You can use Vietnamese to anwser the questions***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghJf5WiN1gDo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH9lSjFfr3Kw"
      },
      "source": [
        "## Question 1A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZNqZuECjNso",
        "outputId": "9c4d5ce4-de58-41b4-9274-d8a7fb8020d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z17reduceBlksKernel3PiS_i' for 'sm_52'\n",
            "ptxas info    : Function properties for _Z17reduceBlksKernel3PiS_i\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 10 registers, 340 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z17reduceBlksKernel2PiS_i' for 'sm_52'\n",
            "ptxas info    : Function properties for _Z17reduceBlksKernel2PiS_i\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 14 registers, 340 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z17reduceBlksKernel1PiS_i' for 'sm_52'\n",
            "ptxas info    : Function properties for _Z17reduceBlksKernel1PiS_i\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 15 registers, 340 bytes cmem[0]\n"
          ]
        }
      ],
      "source": [
        "!nvcc HW2_P1.cu -o HW2_P1 --ptxas-options=-v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVFUj14OYUyy",
        "outputId": "9f97c086-482e-4838-c36e-8eac9a63fd48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num blocks per SM: 16\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15835398144 bytes\n",
            "****************************\n",
            "\n",
            "Input size: 16777217\n",
            "Host time: 43.751263 ms\n",
            "correct result: 2139353559 \n",
            "\n",
            "Kernel 1\n",
            "Grid size: 8193, block size: 1024\n",
            "Kernel time = 2.586208 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 2\n",
            "Grid size: 8193, block size: 1024\n",
            "Kernel time = 2.676928 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 3\n",
            "Grid size: 8193, block size: 1024\n",
            "Kernel time = 1.166560 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n"
          ]
        }
      ],
      "source": [
        "!./HW2_P1 512 --ptxas-options=-v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr2TTpwgs7qA",
        "outputId": "3cc0a02b-b40e-4f5a-af4a-9d8930e6f65f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==527== NVPROF is profiling process 527, command: ./HW2_P1\n",
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num blocks per SM: 16\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15835398144 bytes\n",
            "****************************\n",
            "\n",
            "Input size: 16777217\n",
            "Host time: 43.319008 ms\n",
            "correct result: 2139353559 \n",
            "\n",
            "Kernel 1\n",
            "Grid size: 8193, block size: 1024\n",
            "Kernel time = 2.646112 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 2\n",
            "Grid size: 8193, block size: 1024\n",
            "Kernel time = 2.747808 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 3\n",
            "Grid size: 8193, block size: 1024\n",
            "Kernel time = 1.243328 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "==527== Profiling application: ./HW2_P1\n",
            "==527== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   86.84%  42.933ms         3  14.311ms  14.026ms  14.469ms  [CUDA memcpy HtoD]\n",
            "                    5.45%  2.6961ms         1  2.6961ms  2.6961ms  2.6961ms  reduceBlksKernel2(int*, int*, int)\n",
            "                    5.26%  2.6013ms         1  2.6013ms  2.6013ms  2.6013ms  reduceBlksKernel1(int*, int*, int)\n",
            "                    2.43%  1.2025ms         1  1.2025ms  1.2025ms  1.2025ms  reduceBlksKernel3(int*, int*, int)\n",
            "                    0.01%  5.9520us         3  1.9840us  1.6640us  2.1440us  [CUDA memcpy DtoH]\n",
            "      API calls:   79.65%  224.33ms         8  28.041ms     905ns  224.32ms  cudaEventCreate\n",
            "                   15.79%  44.464ms         6  7.4107ms  22.600us  15.111ms  cudaMemcpy\n",
            "                    2.31%  6.5127ms         3  2.1709ms  1.2055ms  2.7028ms  cudaDeviceSynchronize\n",
            "                    1.37%  3.8561ms         6  642.69us  180.21us  1.0966ms  cudaFree\n",
            "                    0.34%  962.95us         1  962.95us  962.95us  962.95us  cuDeviceGetPCIBusId\n",
            "                    0.29%  829.54us         6  138.26us  73.152us  250.68us  cudaMalloc\n",
            "                    0.10%  272.65us         8  34.080us  5.7980us  80.849us  cudaEventSynchronize\n",
            "                    0.04%  126.08us       101  1.2480us     151ns  52.517us  cuDeviceGetAttribute\n",
            "                    0.03%  94.421us         1  94.421us  94.421us  94.421us  cudaGetDeviceProperties\n",
            "                    0.03%  78.700us         3  26.233us  24.100us  28.093us  cudaLaunchKernel\n",
            "                    0.02%  50.059us         8  6.2570us  2.8430us  13.515us  cudaEventRecord\n",
            "                    0.01%  24.814us         1  24.814us  24.814us  24.814us  cuDeviceGetName\n",
            "                    0.00%  13.189us         8  1.6480us     775ns  2.5290us  cudaEventDestroy\n",
            "                    0.00%  8.5330us         4  2.1330us  1.8170us  2.5230us  cudaEventElapsedTime\n",
            "                    0.00%  2.1560us         3     718ns     256ns  1.5730us  cuDeviceGetCount\n",
            "                    0.00%     930ns         3     310ns     255ns     368ns  cudaGetLastError\n",
            "                    0.00%     906ns         2     453ns     206ns     700ns  cuDeviceGet\n",
            "                    0.00%     540ns         1     540ns     540ns     540ns  cuModuleGetLoadingMode\n",
            "                    0.00%     386ns         1     386ns     386ns     386ns  cuDeviceTotalMem\n",
            "                    0.00%     260ns         1     260ns     260ns     260ns  cuDeviceGetUuid\n"
          ]
        }
      ],
      "source": [
        "!nvprof ./HW2_P1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae8_FYw1pBdg"
      },
      "source": [
        "### Nhận xét về thời gian thực thi các công việc trong GPU activities\n",
        "**Thao tác với dữ liệu trên bộ nhớ**<br>\n",
        "* _**[CUDA memcpy HtoD]**_: copy dữ liệu từ host sang device ~ Chiếm lượng thời gian lớn nhất trong quá trình thực hiện reduce.\n",
        "* _**[CUDA memcpy DtoH]**_: Copy dữ liệu từ device sang host ~ Do chỉ copy 1 phần tử giá trị cuối cùng nên không tốn quá nhiều thời gian để thực thi.\n",
        "\n",
        "**Các hàm kernel chạy trên GPU**<br>\n",
        "* _**Thời gian**_: Nhanh chậm tùy thuộc vào giải thuật đưa ra.\n",
        "\n",
        "<u>_**Nhận xét</u>**_: Đa số thời gian đều được dùng trong giao đoạn đọc ghi dữ liệu trên bộ nhớ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9wMWgeV--5b"
      },
      "source": [
        "## Question 1B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMsckPIh_Ije",
        "outputId": "95c16339-d4ac-4c3a-967d-45a82e693913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num blocks per SM: 16\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15835398144 bytes\n",
            "****************************\n",
            "\n",
            "Input size: 16777217\n",
            "Host time: 46.520416 ms\n",
            "correct result: 2139353559 \n",
            "\n",
            "Kernel 1\n",
            "Grid size: 8193, block size: 1024\n",
            "Kernel time = 2.590432 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 2\n",
            "Grid size: 8193, block size: 1024\n",
            "Kernel time = 2.678432 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 3\n",
            "Grid size: 8193, block size: 1024\n",
            "Kernel time = 1.168288 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n"
          ]
        }
      ],
      "source": [
        "!./HW2_P1 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydvO00hC_JMW",
        "outputId": "9474d4c7-ba9e-493f-917c-bda813ccf28c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num blocks per SM: 16\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15835398144 bytes\n",
            "****************************\n",
            "\n",
            "Input size: 16777217\n",
            "Host time: 43.852383 ms\n",
            "correct result: 2139353559 \n",
            "\n",
            "Kernel 1\n",
            "Grid size: 16385, block size: 512\n",
            "Kernel time = 1.881216 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 2\n",
            "Grid size: 16385, block size: 512\n",
            "Kernel time = 1.984736 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 3\n",
            "Grid size: 16385, block size: 512\n",
            "Kernel time = 0.929056 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n"
          ]
        }
      ],
      "source": [
        "!./HW2_P1 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoxamhSa_Jjc",
        "outputId": "4c4fbdbf-1e04-496c-bdb3-8ff7864d2b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num blocks per SM: 16\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15835398144 bytes\n",
            "****************************\n",
            "\n",
            "Input size: 16777217\n",
            "Host time: 44.167168 ms\n",
            "correct result: 2139353559 \n",
            "\n",
            "Kernel 1\n",
            "Grid size: 32769, block size: 256\n",
            "Kernel time = 1.540992 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 2\n",
            "Grid size: 32769, block size: 256\n",
            "Kernel time = 1.591776 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 3\n",
            "Grid size: 32769, block size: 256\n",
            "Kernel time = 0.785408 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n"
          ]
        }
      ],
      "source": [
        "!./HW2_P1 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF_Kjjqe_J3F",
        "outputId": "80ef39ff-e015-45b8-91ff-36b070de280e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num blocks per SM: 16\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15835398144 bytes\n",
            "****************************\n",
            "\n",
            "Input size: 16777217\n",
            "Host time: 44.302368 ms\n",
            "correct result: 2139353559 \n",
            "\n",
            "Kernel 1\n",
            "Grid size: 65537, block size: 128\n",
            "Kernel time = 1.340928 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 2\n",
            "Grid size: 65537, block size: 128\n",
            "Kernel time = 1.373472 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n",
            "\n",
            "Kernel 3\n",
            "Grid size: 65537, block size: 128\n",
            "Kernel time = 0.714592 ms\n",
            "Kernel result: 2139353559 \n",
            "CORRECT :)\n"
          ]
        }
      ],
      "source": [
        "!./HW2_P1 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sOR-M3PugpL",
        "outputId": "27216876-367a-4809-b753-762558735325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1024: 1, 512: 1, 257: 1, 128: 1}\n",
            "{1024: 8193, 512: 16385, 257: 32641, 128: 65537}\n"
          ]
        }
      ],
      "source": [
        "n = (1 << 24)+1;\n",
        "\n",
        "# Get grid size\n",
        "def getGridSz(n, blk_sizes = [1024, 512, 257, 128]):\n",
        "    dic = {}\n",
        "    for blk_sz in blk_sizes:\n",
        "        dic[blk_sz] = (int((((n-1)>>1)) / blk_sz + 1))\n",
        "    return dic\n",
        "\n",
        "# Get Num blocks/SM\n",
        "def getBlkPerSM(grid_sizes, blk_sizes = [1024, 512, 257, 128]):\n",
        "    dic = {}\n",
        "    for grid_sz, blk_sz in zip(grid_sizes, blk_sizes):\n",
        "        dic[blk_sz] = (int(grid_sz/blk_sz))\n",
        "    return dic\n",
        "\n",
        "grid_szs = getGridSz(n)\n",
        "blk_per_SM = getBlkPerSM(grid_szs)\n",
        "\n",
        "print(blk_per_SM)\n",
        "print(grid_szs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kNR-xsCSWen"
      },
      "source": [
        "Maximum number of resident blocks per SM = 16 <br>\n",
        "Maximum number of resident threads per SM 1024 <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9PXsn1C_L4L"
      },
      "source": [
        "Block size | Grid size | Num blocks / SM | Occupancy (%) | Kernel time (ms)\n",
        "--- | --- | --- | --- | ---\n",
        "1024 | 8193 | 1 | 1 | 2.591584\n",
        "512 | 16385 | 2 | 1 | 1.877888\n",
        "256 | 32641 | 4 | 1 | 1.538240\n",
        "128 | 65537 | 8 | 1 | 1.337952"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c811YinAqrd"
      },
      "source": [
        "#### Từ bảng biểu đã điền, bạn thử suy nghĩ và giải thích xem tại sao khi thay đổi block size thì “kernel time” lại thay đổi như vậy?\n",
        "* _**tài nguyên**_ với bloksize nhỏ có thể dấn đến khả năng sử dụng các tài nguyên có sẵn trong SM tốt nhơn, từ đó giúp giảm xung đột tài nguyên và tối ưu hóa việc sử dụng bộ nhớ\n",
        " trong và bộ nhớ đệm, giúp cải thiện hiệu suất tổng thể.\n",
        "* _**Warp**_ Dễ dẫn đến các wrap phân kì kếu ko kiểm soát tốt đối với giải thuật đưa ra (kernel 1).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaPQCny1077R"
      },
      "source": [
        "## Question 2A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vbDf8XqIGFW6"
      },
      "outputs": [],
      "source": [
        "!nvcc HW2_P2.cu -o HW2_P2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IfmucpNibmm",
        "outputId": "8024722d-9348-4cf2-9fec-a0797915876b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15835398144 bytes\n",
            "****************************\n",
            "\n",
            "Processing time (use host): 3942.777100 ms\n",
            "\n",
            "Basic Matrix Multiplication:\n",
            "Grid size: 32 * 32, block size: 32 * 32\n",
            "Processing time (use device): 8.511712 ms\n",
            "Error between device result and host result: 0.000004\n",
            "\n",
            "Shared memory Matrix Multiplication:\n",
            "Grid size: 32 * 32, block size: 32 * 32\n",
            "Processing time (use device): 5.509312 ms\n",
            "Error between device result and host result: 0.000004"
          ]
        }
      ],
      "source": [
        "!./HW2_P2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1e6I3okFqfO",
        "outputId": "18bc7f1a-deeb-4751-9e8a-6995ab74fa99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==17410== NVPROF is profiling process 17410, command: ./HW2_P2\n",
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15835398144 bytes\n",
            "****************************\n",
            "\n",
            "Processing time (use host): 3595.703369 ms\n",
            "\n",
            "Basic Matrix Multiplication:\n",
            "Grid size: 32 * 32, block size: 32 * 32\n",
            "Processing time (use device): 8.116672 ms\n",
            "Error between device result and host result: 0.000004\n",
            "\n",
            "Shared memory Matrix Multiplication:\n",
            "Grid size: 32 * 32, block size: 32 * 32\n",
            "Processing time (use device): 5.278176 ms\n",
            "==17410== Profiling application: ./HW2_P2\n",
            "Error between device result and host result: 0.000004==17410== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   34.90%  3.2693ms         1  3.2693ms  3.2693ms  3.2693ms  matrix_multiplication_kernel1(float*, float*, float*, int, int, int)\n",
            "                   28.21%  2.6426ms         1  2.6426ms  2.6426ms  2.6426ms  matrix_multiplication_kernel2(float*, float*, float*, int, int, int)\n",
            "                   23.68%  2.2177ms         2  1.1089ms  619.22us  1.5985ms  [CUDA memcpy DtoH]\n",
            "                   13.21%  1.2370ms         4  309.25us  290.49us  358.74us  [CUDA memcpy HtoD]\n",
            "      API calls:   93.58%  218.89ms         6  36.481ms     943ns  218.87ms  cudaEventCreate\n",
            "                    5.09%  11.911ms         6  1.9852ms  443.26us  6.2796ms  cudaMemcpy\n",
            "                    0.56%  1.2986ms         1  1.2986ms  1.2986ms  1.2986ms  cuDeviceGetPCIBusId\n",
            "                    0.31%  713.37us         6  118.89us  111.66us  138.41us  cudaFree\n",
            "                    0.27%  625.98us         6  104.33us  66.664us  208.16us  cudaMalloc\n",
            "                    0.06%  146.95us       101  1.4540us     138ns  58.893us  cuDeviceGetAttribute\n",
            "                    0.04%  90.768us         1  90.768us  90.768us  90.768us  cudaGetDeviceProperties\n",
            "                    0.03%  68.006us         2  34.003us  22.721us  45.285us  cudaLaunchKernel\n",
            "                    0.03%  58.537us         6  9.7560us  3.0780us  22.456us  cudaEventRecord\n",
            "                    0.02%  43.315us         6  7.2190us  6.0460us  9.0540us  cudaEventSynchronize\n",
            "                    0.01%  25.011us         1  25.011us  25.011us  25.011us  cuDeviceGetName\n",
            "                    0.00%  9.0930us         6  1.5150us     886ns  2.8660us  cudaEventDestroy\n",
            "                    0.00%  7.7700us         3  2.5900us  2.1820us  2.9680us  cudaEventElapsedTime\n",
            "                    0.00%  2.5430us         2  1.2710us     328ns  2.2150us  cuDeviceGet\n",
            "                    0.00%  1.8660us         3     622ns     239ns  1.3080us  cuDeviceGetCount\n",
            "                    0.00%     601ns         2     300ns     254ns     347ns  cudaGetLastError\n",
            "                    0.00%     435ns         1     435ns     435ns     435ns  cuModuleGetLoadingMode\n",
            "                    0.00%     403ns         1     403ns     403ns     403ns  cuDeviceGetUuid\n",
            "                    0.00%     376ns         1     376ns     376ns     376ns  cuDeviceTotalMem\n"
          ]
        }
      ],
      "source": [
        "!nvprof ./HW2_P2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG1mOFWW7zlB"
      },
      "source": [
        "### Nhận xét về thời gian thực thi các công việc trong GPU activities\n",
        "**Thao tác với dữ liệu trên bộ nhớ**<br>\n",
        "* _**[CUDA memcpy HtoD]**_: copy dữ liệu từ host sang device ~ Chiếm lượng thời gian tương đối lớn trong quá trình thực hiện reduce.\n",
        "* _**[CUDA memcpy DtoH]**_: Copy dữ liệu từ device sang host ~ Do chỉ copy 1 ma trận ouput nên không tốn quá nhiều thời gian bằng việc copy từ host sang device (do host phải copy 2 ma trận qua device).\n",
        "\n",
        "**Các hàm kernel chạy trên GPU**<br>\n",
        "* _**Thời gian**_: Nhanh chậm tùy thuộc vào giải thuật đưa ra (ở đây nhắm tới việc cải tiến kernel 1 sang kernel 2 bằng cách sử dụng share memory trên mỗi SM để tăng thời gian truy cập dữ liệu).\n",
        "\n",
        "<u>_**Nhận xét</u>**_: Đa số thời gian đều được dùng trong giao đoạn thực hiện kernel (tùy thuộc vào các kích thước của ma trận đưa vào, có thể với kích thước nhỏ sẽ tốn thời gian trong giai đoạn đọc ghi hơn là trong kernel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwzjJVcZE2Yc"
      },
      "source": [
        "## Question 2B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q1H5hI077S"
      },
      "source": [
        "**For Basic Matrix Multipication**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ0grwJf077S"
      },
      "source": [
        "1. How many floating operations are being performed in your matrix multiply\n",
        "kernel? Explain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE1YHZ2l077S"
      },
      "source": [
        "Để có được một phần tử của ma trận output C thì cần 2 phép toán trong n lần lặp của kernel, phép toán += và phép toán *\n",
        "\n",
        "* _**val += A[row * n + i] * B[i * k + col]**_ <br>\n",
        "Khi đó số lượng phép toán là: **gridsize.blocksize.2.n.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt-A4u7w077S"
      },
      "source": [
        "2. How many global memory reads are being performed by your kernel? Explain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHXMnmQT077T"
      },
      "source": [
        "Đọc từ global mem 2 phần tử trong 1 lần tính toán (phần tử _**A[row * n + i]**_ và _**B[row * n + i]**_)<br>\n",
        "Kernel lặp _**n**_ lần để có được giá trị val → số lần đọc là **gridsize.blocksize.2.n**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1e-XX9I077T"
      },
      "source": [
        "3. How many global memory writes are being performed by your kernel? Explain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv2HixBK077T"
      },
      "source": [
        "Viết giá trị tính toán được (val) xuống mảng output C 1 lần trong mỗi lần lặp của kernel (gồm _**n**_ lần lặp. Do đó số lần ghi sẽ là **gridsize.blocksize.n**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRG62U3c077T"
      },
      "source": [
        "**For Tiled Matrix Multipication**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00sMOQLZ077T"
      },
      "source": [
        "1. How many floating operations are being performed in your matrix multiply\n",
        "kernel? Explain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic4bMqfR077T"
      },
      "source": [
        "Ứng với n lần lặp của kernel, thực thi 2 phép toán đó là phép toán += và phép toán *\n",
        "\n",
        "* _**val += s_A[ty][j] * s_B[j][tx]**_ <br>\n",
        "Khi đó số lượng phép toán là: **2.TILE_WIDTH = 2.32 = 64**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwt2USrR077T"
      },
      "source": [
        "2. How many global memory reads are being performed by your kernel? Explain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phVLxgvz077U"
      },
      "source": [
        "Mỗi block sẽ khởi tạo share memory và đọc dữ liệu từ global memory lên share memmory, khi đó mỗi thread trong block sẽ thực thi hành động này. Mà mỗi block sẽ đọc lên các giá trị A và B (do đó đọc 2 lần cho mỗi lần lặp) tương ứng với chiều dài và chiều rộng của mảng. Đối trường hợp chiều dài và rộng ko chia hết cho blocksz thì sẽ ko đọc và gán giá trị 0, tạm coi trường hợp gán là độc giá trị từ global lên share thì số lượng phần tử đọc lên như sau:\n",
        "_**gridsize.blocksize.2.(n + TILE_WIDTH - 1) / TILE_WIDTH**_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfFu6_-s077U"
      },
      "source": [
        "3. How many global memory writes are being performed by your kernel? Explain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC7reqmO077U"
      },
      "source": [
        "Mỗi kernel ghi duy nhất giá trị output của mảng C xuống global memory, do đó. _**Số lần ghi**_ của 1 kernel bằng số số lần gọi của 1 _**tile**_, số lượng _**tile = gridsize.blocksize.(n + TILE_WIDTH - 1) / TILE_WIDTH**_"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
